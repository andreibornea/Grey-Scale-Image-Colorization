# Grey-Scale-Image-Colorization
Model's Arhitecture
1. Conditional Generative Adversarial Networks (cGANs)

The base model will be a conditional GAN (cGAN). In this model, a generator network learns to map grayscale images to colorized images. The generator takes a grayscale image as input and produces a 2-channel image (for *a and *b color channels in Lab color space).

The discriminator network then takes these generated color channels, combines them with the original grayscale image to form a 3-channel image, and learns to classify these images as "real" or "fake". Real images for the discriminator will be true color images, while fake images will be the ones generated by the generator network.

The grayscale images serve as a "condition" for both the generator and the discriminator. Both networks are expected to take this condition into account when generating and evaluating images, respectively.

In addition, the architecture includes dropout layers to introduce noise into the generator network.

2. Additional Architectural Features

Several architectural features will be used to enhance the capabilities of the model:

Residual Connections: These are used to allow the gradient to flow directly through several layers, alleviating the vanishing gradient problem and enabling the model to learn more complex functions.

Dilated Convolutions: This allows the model to capture a wider context without increasing computation or parameter count.

Attention Mechanisms: These allow the model to focus on specific parts of the image when colorizing a particular pixel, improving the ability to capture dependencies between different parts of the image.

3. Loss Function

The model will be trained using a combination of adversarial loss from the cGAN framework and L1 loss. The adversarial loss encourages the generator to create images that the discriminator cannot distinguish from real images. The L1 loss acts as a regression task to help the model learn the true color values of the image pixels.

To better address the multimodal nature of the colorization task, the model will be trained to predict a distribution of possible colors for each pixel and will be rewarded more for predicting rare colors. The final colorization will be produced by taking the annealed mean of the predicted color distribution.
